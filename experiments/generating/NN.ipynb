{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append(\"../../\")\n",
    "from utils.evaluation import evaluate\n",
    "from utils.metrics import Metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune\n",
    "from neptune_pytorch import NeptuneLogger\n",
    "from neptune.utils import stringify_unsupported\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "from git import Repo\n",
    "\n",
    "# Get the git root directory\n",
    "repo = Repo(\".\", search_parent_directories=True)\n",
    "git_root = repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "# Load data\n",
    "X_Train_pd = pickle.load(open(f\"{git_root}/data/splits/train/X_pandas.pck\", \"rb\"))\n",
    "y_Train_pd = pickle.load(open(f\"{git_root}/data/splits/train/y_pandas.pck\", \"rb\"))\n",
    "\n",
    "X_Val_pd = pickle.load(open(f\"{git_root}/data/splits/val/X_pandas.pck\", \"rb\"))\n",
    "y_Val_pd = pickle.load(open(f\"{git_root}/data/splits/val/y_pandas.pck\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = torch.tensor(X_Train_pd.values, dtype=torch.float32)\n",
    "y_Train = torch.tensor(y_Train_pd.values, dtype=torch.float32)\n",
    "\n",
    "X_Val = torch.tensor(X_Val_pd.values, dtype=torch.float32)\n",
    "y_Val = torch.tensor(y_Val_pd.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleNetwork(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.layers = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(5045, 5045),\n",
    "#             torch.nn.LeakyReLU(0.1),\n",
    "#             torch.nn.Linear(5045, 5045),\n",
    "#             torch.nn.LeakyReLU(0.1),\n",
    "#             torch.nn.Linear(5045, 2000),\n",
    "#             torch.nn.LeakyReLU(0.1),\n",
    "#             torch.nn.Linear(2000, 1000),\n",
    "#             torch.nn.LeakyReLU(0.1),\n",
    "#             torch.nn.Linear(1000, 300),\n",
    "#             torch.nn.LeakyReLU(0.1),\n",
    "#             torch.nn.Linear(300, 105),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.layers(x)\n",
    "\n",
    "class SimpleNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5045, 5045),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.BatchNorm1d(5045),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(5045, 5045),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.BatchNorm1d(5045),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(5045, 2000),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.BatchNorm1d(2000),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(2000, 1000),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.BatchNorm1d(1000),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(1000, 300),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.BatchNorm1d(300),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(300, 105),\n",
    "        )\n",
    "\n",
    "        # Apply Xavier initialization\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_normal_(layer.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_from_logits(y_hat: torch.Tensor, threshold = 0.5) -> torch.Tensor:\n",
    "    with torch.no_grad():\n",
    "        y_pred_tensor = (torch.sigmoid(y_hat) > threshold).float()\n",
    "    return y_pred_tensor\n",
    "\n",
    "\n",
    "def evaluate_from_dataframe(X: pd.DataFrame):\n",
    "    X_tensor = torch.tensor(X.to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    #model: a pytorch model, which transforms X -> y in torch.Tensor format\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    y_pred_tensor = label_from_logits(model(X_tensor))\n",
    "    \n",
    "    return pd.DataFrame(y_pred_tensor.numpy())\n",
    "\n",
    "def training(model, optimizer, criterion, train_dataloader, val_dataloder, epochs, device, neptune_logger=None, run = None):\n",
    "    criterion = criterion.to(device)\n",
    "    model = model.to(device)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_acc = 0\n",
    "        val_acc = 0\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        model.train()\n",
    "        for x,y in train_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_acc += Metrics.calculate_accuracy(y.cpu().numpy(), label_from_logits(y_pred).cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            y_preds = np.array([])\n",
    "            y_trues = np.array([])\n",
    "            for x,y in val_dataloder:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                y_pred = model(x)\n",
    "                val_loss += criterion(y_pred, y)\n",
    "                y_pred = label_from_logits(y_pred).cpu().numpy()\n",
    "                y = y.cpu().numpy()\n",
    "                y_preds = np.vstack((y_preds, y_pred)) if y_preds.size else y_pred\n",
    "                y_trues = np.vstack((y_trues, y)) if y_trues.size else y\n",
    "\n",
    "            val_acc = Metrics.calculate_accuracy(y_preds, y_trues)\n",
    "            val_precision = Metrics.calculate_precision(y_preds, y_trues)\n",
    "            val_recall = Metrics.calculate_recall(y_preds, y_trues)\n",
    "            val_f1 = Metrics.calculate_f1_score(y_preds, y_trues)\n",
    "\n",
    "        if neptune_logger:\n",
    "            run[neptune_logger.base_namespace]['train_loss'].append(train_loss)\n",
    "            run[neptune_logger.base_namespace]['train_acc'].append(train_acc/len(train_dataloader))\n",
    "            run[neptune_logger.base_namespace]['val_loss'].append(val_loss)\n",
    "            run[neptune_logger.base_namespace]['val_acc'].append(val_acc)\n",
    "            run[neptune_logger.base_namespace]['val_precision'].append(val_precision)\n",
    "            run[neptune_logger.base_namespace]['val_recall'].append(val_recall)\n",
    "            run[neptune_logger.base_namespace]['val_f1'].append(val_f1)\n",
    "\n",
    "        print(f\"Epoch: {epoch} Train Loss: {train_loss} Train Acc: {train_acc/len(train_dataloader)} Val Loss: {val_loss} Val Acc: {val_acc}\")\n",
    "        #print(f\"CUDA memory allocated: {torch.cuda.memory_allocated(device)/1024**3:.2f} GB\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_Train, y_Train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_Val, y_Val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"batch_size\": 512,\n",
    "    \"lr\": 0.001,\n",
    "    \"epochs\": 50,\n",
    "    \"shuffle\": True,\n",
    "    \"model_name\": \"SimpleNetwork\",\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"criterion\": \"BCEWithLogitsLoss\",\n",
    "    \"device\": device,\n",
    "    \"LayerInitialization\": \"Xavier\",\n",
    "    \"drop_out\": True,\n",
    "    \"layerNormaization\": False,\n",
    "    \"batchNormaization\": True,\n",
    "    \"Threshold\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=parameters[\"batch_size\"], shuffle=parameters[\"shuffle\"])\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=parameters[\"batch_size\"], shuffle=False)\n",
    "\n",
    "model = SimpleNetwork()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=parameters[\"lr\"])\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/JPL/rna-sequencing/e/RNAS-142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af3aeec2f3d4f3494205d37074cb781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 54.263460136950016 Train Acc: 0.06099136884427833 Val Loss: 1.2756699323654175 Val Acc: 0.13168859649122808\n",
      "Epoch: 1 Train Loss: 7.525874361395836 Train Acc: 0.1636092669901937 Val Loss: 0.7360912561416626 Val Acc: 0.20877192982456141\n",
      "Epoch: 2 Train Loss: 5.341028776019812 Train Acc: 0.26032838539573455 Val Loss: 0.5790475606918335 Val Acc: 0.31030701754385964\n",
      "Epoch: 3 Train Loss: 4.3627725429832935 Train Acc: 0.35589655046820995 Val Loss: 0.5163073539733887 Val Acc: 0.3712719298245614\n",
      "Epoch: 4 Train Loss: 3.7141436003148556 Train Acc: 0.426295761829167 Val Loss: 0.4726189076900482 Val Acc: 0.41853070175438595\n",
      "Epoch: 5 Train Loss: 3.2597478330135345 Train Acc: 0.4823995299480214 Val Loss: 0.45921918749809265 Val Acc: 0.44956140350877194\n",
      "Epoch: 6 Train Loss: 2.901451548561454 Train Acc: 0.5268239528072503 Val Loss: 0.45880505442619324 Val Acc: 0.4611842105263158\n",
      "Epoch: 7 Train Loss: 2.6060511264950037 Train Acc: 0.5680087617722316 Val Loss: 0.45976361632347107 Val Acc: 0.4654605263157895\n",
      "Epoch: 8 Train Loss: 2.318992068991065 Train Acc: 0.6062612405554216 Val Loss: 0.4627414047718048 Val Acc: 0.47730263157894737\n",
      "Epoch: 9 Train Loss: 2.0953067280352116 Train Acc: 0.6359941318858344 Val Loss: 0.47051534056663513 Val Acc: 0.47543859649122805\n",
      "Epoch: 10 Train Loss: 1.8246698919683695 Train Acc: 0.6743479745230823 Val Loss: 0.4944964051246643 Val Acc: 0.47719298245614034\n",
      "Epoch: 11 Train Loss: 1.610206350684166 Train Acc: 0.7023720188456181 Val Loss: 0.5080484747886658 Val Acc: 0.47478070175438597\n",
      "Epoch: 12 Train Loss: 1.3813783437944949 Train Acc: 0.7371479843193205 Val Loss: 0.5311657190322876 Val Acc: 0.47653508771929826\n",
      "Epoch: 13 Train Loss: 1.1812231969088316 Train Acc: 0.7677146025071672 Val Loss: 0.546250581741333 Val Acc: 0.47828947368421054\n",
      "Epoch: 14 Train Loss: 1.025475934613496 Train Acc: 0.7884277853970743 Val Loss: 0.5639758110046387 Val Acc: 0.47785087719298247\n",
      "Epoch: 15 Train Loss: 0.8929243660531938 Train Acc: 0.8128056091418161 Val Loss: 0.568386435508728 Val Acc: 0.4786184210526316\n",
      "Epoch: 16 Train Loss: 0.7607430280186236 Train Acc: 0.8365772383148461 Val Loss: 0.5832551121711731 Val Acc: 0.4763157894736842\n",
      "Epoch: 17 Train Loss: 0.6626249644905329 Train Acc: 0.8565161416050424 Val Loss: 0.6080608367919922 Val Acc: 0.4787280701754386\n",
      "Epoch: 18 Train Loss: 0.5950052151456475 Train Acc: 0.8672231369564344 Val Loss: 0.6134785413742065 Val Acc: 0.4820175438596491\n",
      "Epoch: 19 Train Loss: 0.5286781259346753 Train Acc: 0.8806807192448356 Val Loss: 0.6151250004768372 Val Acc: 0.481140350877193\n",
      "Epoch: 20 Train Loss: 0.46101236692629755 Train Acc: 0.896572551610267 Val Loss: 0.6346588134765625 Val Acc: 0.4847587719298246\n",
      "Epoch: 21 Train Loss: 0.42304761428385973 Train Acc: 0.9038907392894463 Val Loss: 0.6460696458816528 Val Acc: 0.48103070175438595\n",
      "Epoch: 22 Train Loss: 0.41151756700128317 Train Acc: 0.9064826606583073 Val Loss: 0.6532504558563232 Val Acc: 0.4917763157894737\n",
      "Epoch: 23 Train Loss: 0.3737040169071406 Train Acc: 0.9149402366670686 Val Loss: 0.6613746285438538 Val Acc: 0.48388157894736844\n",
      "Epoch: 24 Train Loss: 0.3504134814720601 Train Acc: 0.9195625226067037 Val Loss: 0.671168327331543 Val Acc: 0.48541666666666666\n",
      "Epoch: 25 Train Loss: 0.32178927143104374 Train Acc: 0.9263385680411542 Val Loss: 0.6779890060424805 Val Acc: 0.48530701754385963\n",
      "Epoch: 26 Train Loss: 0.3264940275112167 Train Acc: 0.9245403931556948 Val Loss: 0.7041717171669006 Val Acc: 0.48004385964912283\n",
      "Epoch: 27 Train Loss: 0.3281251871958375 Train Acc: 0.924057645838357 Val Loss: 0.7011563777923584 Val Acc: 0.4831140350877193\n",
      "Epoch: 28 Train Loss: 0.3112336170161143 Train Acc: 0.9282023651635721 Val Loss: 0.7015707492828369 Val Acc: 0.4911184210526316\n",
      "Epoch: 29 Train Loss: 0.27627473801840097 Train Acc: 0.93602381365043 Val Loss: 0.6950995326042175 Val Acc: 0.4926535087719298\n",
      "Epoch: 30 Train Loss: 0.2620922435307875 Train Acc: 0.9384634014213755 Val Loss: 0.7026427388191223 Val Acc: 0.4849780701754386\n",
      "Epoch: 31 Train Loss: 0.24953912943601608 Train Acc: 0.9424694453654583 Val Loss: 0.724890410900116 Val Acc: 0.4905701754385965\n",
      "Epoch: 32 Train Loss: 0.2673584573203698 Train Acc: 0.9387376123636899 Val Loss: 0.7186260223388672 Val Acc: 0.49100877192982456\n",
      "Epoch: 33 Train Loss: 0.26480474486015737 Train Acc: 0.9386162583226162 Val Loss: 0.7377743721008301 Val Acc: 0.48037280701754387\n",
      "Epoch: 34 Train Loss: 0.2613158688182011 Train Acc: 0.9405940832395574 Val Loss: 0.7183437943458557 Val Acc: 0.4849780701754386\n",
      "Epoch: 35 Train Loss: 0.24195294186938554 Train Acc: 0.9443684608016504 Val Loss: 0.739109218120575 Val Acc: 0.493640350877193\n",
      "Epoch: 36 Train Loss: 0.21620949322823435 Train Acc: 0.9499793713829275 Val Loss: 0.7510905265808105 Val Acc: 0.48837719298245613\n",
      "Epoch: 37 Train Loss: 0.21449024422327057 Train Acc: 0.9498832405621198 Val Loss: 0.7444159984588623 Val Acc: 0.4956140350877193\n",
      "Epoch: 38 Train Loss: 0.2143390369019471 Train Acc: 0.9509748512981271 Val Loss: 0.7553712129592896 Val Acc: 0.4917763157894737\n",
      "Epoch: 39 Train Loss: 0.21477714902721345 Train Acc: 0.9504747303103985 Val Loss: 0.764268696308136 Val Acc: 0.4911184210526316\n",
      "Epoch: 40 Train Loss: 0.2198652426013723 Train Acc: 0.948367701802508 Val Loss: 0.7519830465316772 Val Acc: 0.49089912280701753\n",
      "Epoch: 41 Train Loss: 0.21524541854159907 Train Acc: 0.9501811048147256 Val Loss: 0.7617791295051575 Val Acc: 0.48903508771929827\n",
      "Epoch: 42 Train Loss: 0.21843826898839325 Train Acc: 0.9494892454887067 Val Loss: 0.7613698244094849 Val Acc: 0.49155701754385966\n",
      "Epoch: 43 Train Loss: 0.1987728302483447 Train Acc: 0.9535394562334217 Val Loss: 0.7557902932167053 Val Acc: 0.4962719298245614\n",
      "Epoch: 44 Train Loss: 0.18566230201395229 Train Acc: 0.956371416837473 Val Loss: 0.7648103833198547 Val Acc: 0.49473684210526314\n",
      "Epoch: 45 Train Loss: 0.1815114349592477 Train Acc: 0.9578869555970848 Val Loss: 0.7854495048522949 Val Acc: 0.4860745614035088\n",
      "Epoch: 46 Train Loss: 0.17822248552693054 Train Acc: 0.9579820398112423 Val Loss: 0.7650595307350159 Val Acc: 0.48848684210526316\n",
      "Epoch: 47 Train Loss: 0.18663286761147901 Train Acc: 0.9565332222255714 Val Loss: 0.7695438861846924 Val Acc: 0.4986842105263158\n",
      "Epoch: 48 Train Loss: 0.18776985380100086 Train Acc: 0.9560961592885084 Val Loss: 0.768598198890686 Val Acc: 0.4903508771929825\n",
      "Epoch: 49 Train Loss: 0.17999719234649092 Train Acc: 0.9572429261949736 Val Loss: 0.7724872827529907 Val Acc: 0.4895833333333333\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 6 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] Still waiting for the remaining 6 operations (0.00% done). Please wait.\n",
      "[neptune] [info   ] All 6 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/JPL/rna-sequencing/e/RNAS-142/metadata\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    api_token=os.getenv(\"NEPTUNE_API_KEY\"),\n",
    "    project=os.getenv(\"NEPTUNE_PROJECT_NAME\"),\n",
    "    name=\"SimpleNetwork - with B.Norm\",\n",
    ")\n",
    "run[\"model/structure\"] = str(model)\n",
    "\n",
    "neptune_logger = NeptuneLogger(run=run, model=model)\n",
    "                               \n",
    "run[neptune_logger.base_namespace][\"hyperparams\"] = stringify_unsupported(parameters)\n",
    "\n",
    "\n",
    "training(model, optimizer, criterion, train_dataloader, val_dataloader, parameters[\"epochs\"], device=device, neptune_logger=neptune_logger, run=run)\n",
    "\n",
    "metrics_test = evaluate(evaluate_from_dataframe)\n",
    "\n",
    "run[\"test\"] = metrics_test.as_dict()\n",
    "\n",
    "neptune_logger.log_model()\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), f\"{git_root}/experiments/generating/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SimpleNetwork()\n",
    "# model.load_state_dict(torch.load(f\"{git_root}/experiments/generating/model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_test = evaluate(evaluate_from_dataframe)\n",
    "\n",
    "# for metric, value in metrics_test:\n",
    "#     print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
